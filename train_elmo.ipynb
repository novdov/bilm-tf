{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "from bilm.training import train, load_options_latest_checkpoint, load_vocab\n",
    "from bilm.data import BidirectionalLMDataset\n",
    "\n",
    "now = datetime.now()\n",
    "date_fmt = '{:%m%d_%H%M}'.format(now)\n",
    "\n",
    "train_prefix = '/media/scatter/scatterdisk/sandbox_temp/data/kakaotalk_sol_elmo/messages/*/*'\n",
    "val_prefix = '/media/scatter/scatterdisk/sandbox_temp/data/kakaotalk_sol_elmo/val/*/*'\n",
    "vocab_file = '/media/scatter/scatterdisk/sandbox_temp/data/kakaotalk_sol_elmo/kakaotalk_sol_unique_tokens.txt'\n",
    "save_dir = '/media/scatter/scatterdisk/elmo_ckpt_{}'.format(date_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load the vocab\n",
    "    vocab = load_vocab(vocab_file, 50)\n",
    "\n",
    "    # define the options\n",
    "    batch_size = 64  # batch size for each GPU\n",
    "    n_gpus = 2\n",
    "\n",
    "    # number of tokens in training data (this for 1B Word Benchmark)\n",
    "    # n_train_tokens = 768648884\n",
    "    # 연애의 과학 토크나이징된 카톡 데이터 (identified_corpus_20180105) 토큰 개수\n",
    "    n_train_tokens = 605918\n",
    "\n",
    "    options = {\n",
    "        'bidirectional': True,\n",
    "        'char_cnn': {\n",
    "            'activation': 'relu',\n",
    "            'embedding': {'dim': 16},\n",
    "            'filters': [[1, 32],\n",
    "                        [2, 32],\n",
    "                        [3, 64],\n",
    "                        [4, 128],\n",
    "                        [5, 256],\n",
    "                        [6, 512],\n",
    "                        [7, 1204]],\n",
    "            'max_characters_per_token': 50,\n",
    "            'n_characters': 261,\n",
    "            'n_highway': 2\n",
    "        },\n",
    "\n",
    "        'dropout': 0.2,\n",
    "        'lstm': {\n",
    "            'cell_clip': 3,\n",
    "            'dim': 1024,\n",
    "            'n_layers': 2,\n",
    "            'proj_clip': 5,\n",
    "            'projection_dim': 256,\n",
    "            'use_skip_connections': True\n",
    "        },\n",
    "\n",
    "        'all_clip_norm_val': 10.0,\n",
    "        'n_epochs': 20,\n",
    "        'n_train_tokens': n_train_tokens,\n",
    "        'batch_size': batch_size,\n",
    "        'n_tokens_vocab': vocab.size,\n",
    "        'unroll_steps': 20,\n",
    "        'n_negative_samples_batch': 4096,\n",
    "    }\n",
    "\n",
    "    prefix = train_prefix\n",
    "    data = BidirectionalLMDataset(prefix,\n",
    "                                  vocab,\n",
    "                                  test=False,\n",
    "                                  shuffle_on_load=True)\n",
    "    tf_save_dir = save_dir\n",
    "    tf_log_dir = save_dir\n",
    "    train(options, data, n_gpus, tf_save_dir, tf_log_dir)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--save_dir', help='Location of checkpoint files')\n",
    "#     parser.add_argument('--vocab_file', help='Vocabulary file')\n",
    "#     parser.add_argument('--train_prefix', help='Prefix for train files')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunwoongenv",
   "language": "python",
   "name": "sunwoongenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
